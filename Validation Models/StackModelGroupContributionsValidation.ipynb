{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab05d53",
   "metadata": {},
   "source": [
    "### Artificial Neural Network for the Prediction of Specific Heat Capacity using a Stacked Model approach and Group Contributions with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy (manipulation of arrays)\n",
    "import numpy as np\n",
    "# Pandas (manipulation of databases)\n",
    "import pandas as pd\n",
    "# Matplotlib (plotting library)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "\n",
    "# Import scikit learn classifier and regressor.\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import the random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Import Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Import Support Vector Regressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Tool for splitting sets. Needed to split training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Tool for splitting sets. Used to apply kFold validation on the data sets\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "# Module to normalized data\n",
    "from sklearn import preprocessing\n",
    "# Module to standardise data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Tool for calculation of the mean square error (mse) and mean absolut error (mae)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Tool for calculating R2 and Cross Validation score\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictates which columns I would like to read from the databse\n",
    "columns = ['Temperature (K)','Density (kg/m3)','Cp (J/g*K)','CH4','CH3','CH2','CH','C']\n",
    "\n",
    "# Read data base, specifies no specific sheet thus reads all of them together\n",
    "d = pd.read_excel('databasegc.xlsx', sheet_name=None, header=0, usecols=columns)\n",
    "\n",
    "# Colates the multiple sheets in the data base\n",
    "df = pd.concat(d.values(), ignore_index=True)\n",
    "\n",
    "# Print data base \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa801df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the database (means, standard deviations, etc.)\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column (output). For this example, wine quality is the target property\n",
    "target = ['Cp (J/g*K)']\n",
    "\n",
    "#Prints target\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a34cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies exact features (inputs) in order\n",
    "features = ['Temperature (K)','Density (kg/m3)','CH4','CH3','CH2','CH','C']\n",
    "\n",
    "#Prints features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input (feature) data and output (target) data from database \n",
    "x_data = df[features].values\n",
    "y_data = df[target].values\n",
    "\n",
    "# Split data for training and testing. In this example, the splits is 80:20\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_data,y_data,test_size=0.2,random_state=40,shuffle=True)\n",
    "\n",
    "# Split training set into training and validation sets (75/25 split)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=40)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fits and transforms x_train data set (standardisation)\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Transforms x_test data set using the mean and standard deviation from the fitted x_train data set\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Create a Gradient Boosting regressor\n",
    "GBR = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.01,max_depth=15,random_state=0,loss='squared_error')\n",
    "GBR.fit(x_train_scaled, y_train.ravel())\n",
    "GBR_preds = GBR.predict(x_test_scaled)\n",
    "\n",
    "# Create an Artificial Neural Network architecture \n",
    "MLP = MLPRegressor(hidden_layer_sizes=(30,10,5),solver='lbfgs',alpha=1e-5,random_state=1,max_iter=50000)\n",
    "MLP.fit(x_train_scaled, y_train.ravel())\n",
    "MLP_preds = MLP.predict(x_test_scaled)\n",
    "\n",
    "# Create a Support Vector regressor\n",
    "SVR = SVR(kernel='rbf', C=200, gamma=15, epsilon=0.01)\n",
    "SVR.fit(x_train_scaled, y_train.ravel())\n",
    "SVR_preds = SVR.predict(x_test_scaled)\n",
    "\n",
    "# Stack the predictions\n",
    "stacked_features = np.column_stack((GBR_preds, MLP_preds, SVR_preds))\n",
    "\n",
    "# Train a meta-model on the stacked features\n",
    "clf = RandomForestRegressor(n_estimators=200,max_depth=10,random_state=1)\n",
    "\n",
    "#Fit the train meta-model\n",
    "clf.fit(stacked_features, y_test.ravel())\n",
    "\n",
    "# Calculates the R2 score after fitting\n",
    "r2_test = clf.score(stacked_features, y_test)\n",
    "\n",
    "# Print the r2 and cross-validation scores\n",
    "print('The R2 for the test data after fitting is: {0:6.5f}'.format(r2_test).rstrip('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the validation set using the mean and standard deviation from the training set\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "\n",
    "# Generate predictions for the validation set using the three base models\n",
    "GBR_val_preds = GBR.predict(x_val_scaled)\n",
    "MLP_val_preds = MLP.predict(x_val_scaled)\n",
    "SVR_val_preds = SVR.predict(x_val_scaled)\n",
    "\n",
    "# Stack the predictions for the validation set\n",
    "stacked_val_features = np.column_stack((GBR_val_preds, MLP_val_preds, SVR_val_preds))\n",
    "\n",
    "# Evaluate the performance of the meta-model using R-squared\n",
    "r2_val = clf.score(stacked_val_features, y_val)\n",
    "print('The R2 for the validation data is: {0:6.5f}'.format(r2_val).rstrip('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimized neural network to predict the output\n",
    "predict_train_set1 = GBR.predict(x_train_scaled)\n",
    "predict_train_set2 = MLP.predict(x_train_scaled)\n",
    "predict_train_set3 = SVR.predict(x_train_scaled)\n",
    "predict_test_set = clf.predict(stacked_features)\n",
    "predict_val_set = clf.predict(stacked_val_features)\n",
    "\n",
    "# Calculates the mean squared error\n",
    "mse = mean_squared_error(y_test, predict_test_set)\n",
    "mse_rounded = round(mse, 5)\n",
    "print(f\"Mean squared error: {mse_rounded}\")\n",
    "\n",
    "# Calculate mean absolute error (MAE)\n",
    "mae = mean_absolute_error(y_test, predict_test_set)\n",
    "mae_rounded = round(mae, 5)\n",
    "print(f\"Mean absolute error: {mae_rounded}\")\n",
    "\n",
    "# Calculate root mean squared error (RMSE)\n",
    "rmse = mean_squared_error(y_test, predict_test_set, squared=False)\n",
    "rmse_rounded = round(rmse, 5)\n",
    "print(f\"Root mean squared error: {rmse_rounded}\")\n",
    "\n",
    "# Calculate average absolute deviation (AAD)\n",
    "summation = 0\n",
    "n = len(y_test)\n",
    "for i in range(0,n):\n",
    "    difference = predict_test_set[i]-y_test[i]\n",
    "    frac = difference/y_test[i]\n",
    "    squared = frac**2\n",
    "    summation = summation + squared\n",
    "    aad = (summation/n)[0]\n",
    "    aad_rounded = str(np.round(aad, 5)).rstrip('0').rstrip('.')\n",
    "print(f\"Average absolute deviation: {aad_rounded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ab6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots a graph comparing the the accuracy of the train and test data sets\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "\n",
    "ax1.plot(y_train, predict_train_set1, marker='o', ls='None', mec='k', mfc='#7FFF00', label='Train GBR', markersize=10)\n",
    "ax1.plot(y_train, predict_train_set2, marker='o', ls='None', mec='k', mfc='#FF7F0E', label='Train MLP', markersize=10)\n",
    "ax1.plot(y_train, predict_train_set3, marker='o', ls='None', mec='k', mfc='#E3CF57', label='Train SVR', markersize=10)\n",
    "ax1.plot(y_val, predict_val_set, marker='o', ls='None', mec='k', mfc='#FFC0CB', label='Validation', markersize=10)\n",
    "ax1.plot(y_test, predict_test_set, marker='o', ls='None', mec='k', mfc='#1F77B4', label='Test', markersize=10)\n",
    "ax1.legend(fontsize=18)\n",
    "\n",
    "ax1.plot([0,26],[0,26],'-k',lw=0.5)\n",
    "\n",
    "ax1.tick_params(axis='both',which='major',labelsize=18,length=8,width=1.5,pad=4,direction='out')\n",
    "ax1.tick_params(axis='both',which='minor',labelsize=18,length=4,width=1,pad=4,direction='out')\n",
    "\n",
    "ax1.set_xlim([0,25])\n",
    "ax1.set_ylim([0,25])\n",
    "ax1.set_xlabel('Output (target)',fontsize=24)\n",
    "ax1.set_ylabel('Output (predicted)',fontsize=24)\n",
    "ax1.set_title('Model Accuracy', fontsize=20)\n",
    "\n",
    "majorLocator = MultipleLocator(5)\n",
    "minorLocator = MultipleLocator(2.5)\n",
    "ax1.xaxis.set_major_locator(majorLocator)\n",
    "ax1.xaxis.set_minor_locator(minorLocator)\n",
    "ax1.yaxis.set_major_locator(majorLocator)\n",
    "ax1.yaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until the user chooses to exit\n",
    "while True:\n",
    "    # Ask the user for input values\n",
    "    temperature = float(input(\"Enter Temperature (K): \"))\n",
    "    density = float(input(\"Enter Density (kg/m3): \"))\n",
    "    CH4 = float(input(\"Enter CH4: \"))\n",
    "    CH3 = float(input(\"Enter CH3: \"))\n",
    "    CH2 = float(input(\"Enter CH2: \"))\n",
    "    CH = float(input(\"Enter CH: \"))\n",
    "    C = float(input(\"Enter C: \"))\n",
    "\n",
    "    # Create a numpy array from the input values and reshape\n",
    "    input_values = np.array([temperature, density, CH4, CH3, CH2, CH, C]).reshape(1, -1)\n",
    "\n",
    "    # Scale the input values to match the training and test data\n",
    "    scaled_input = scaler.transform(input_values)\n",
    "    \n",
    "    # Use the meta-model to make predictions on new data\n",
    "    GBR_pred = GBR.predict(scaled_input)\n",
    "    MLP_pred = MLP.predict(scaled_input)\n",
    "    SVR_pred = SVR.predict(scaled_input)\n",
    "    \n",
    "    # Combine the individual models' predictions with the original input features\n",
    "    stacked_features = np.column_stack((GBR_pred, MLP_pred, SVR_pred))\n",
    "    \n",
    "    # Use the trained meta-model to make predictions on the stacked features\n",
    "    predicted_cp = clf.predict(stacked_features)[0]\n",
    "    \n",
    "    # Round the predicted value to 4 decimal places and remove trailing zeros\n",
    "    predicted_cp_rounded = str(np.round(predicted_cp, 4)).rstrip('0').rstrip('.')\n",
    "\n",
    "    # Print the predicted and actual Cp values\n",
    "    print(f\"Predicted Cp: {predicted_cp_rounded}\")\n",
    "\n",
    "    # Ask the user if they want to enter new input values or exit\n",
    "    choice = input(\"Do you want to enter new input values? (Y/N) \").upper()\n",
    "    if choice != \"Y\":\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
