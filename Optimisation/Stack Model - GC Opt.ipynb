{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab05d53",
   "metadata": {},
   "source": [
    "### Optimisation of Gradient Boosting Regressor in Artificial Neural Network for the Prediction of Specific Heat Capacity using a Stacked Model approach and Group Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy (manipulation of arrays)\n",
    "import numpy as np\n",
    "# Pandas (manipulation of databases)\n",
    "import pandas as pd\n",
    "# Matplotlib (plotting library)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "\n",
    "# Import scikit learn classifier and regressor.\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import the random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Import Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Import Support Vector Regressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Import grid search to finetune the hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Tool for splitting sets. Needed to split training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Tool for splitting sets. Used to apply kFold validation on the data sets\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "# Module to normalized data\n",
    "from sklearn import preprocessing\n",
    "# Module to standardise data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Tool for calculation of the mean square error (mse) and mean absolut error (mae)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Tool for calculating R2 and Cross Validation score\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictates which columns I would like to read from the databse\n",
    "columns = ['Temperature (K)','Density (kg/m3)','Cp (J/g*K)','CH4','CH3','CH2','CH','C']\n",
    "\n",
    "# Read data base, specifies no specific sheet thus reads all of them together\n",
    "d = pd.read_excel('databasegc.xlsx', sheet_name=None, header=0, usecols=columns)\n",
    "\n",
    "# Colates the multiple sheets in the data base\n",
    "df = pd.concat(d.values(), ignore_index=True)\n",
    "\n",
    "# Print data base \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa801df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the database (means, standard deviations, etc.)\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column (output). For this example, wine quality is the target property\n",
    "target = ['Cp (J/g*K)']\n",
    "\n",
    "#Prints target\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a34cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies exact features (inputs) in order\n",
    "features = ['Temperature (K)','Density (kg/m3)','CH4','CH3','CH2','CH','C']\n",
    "\n",
    "#Prints features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c09ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input (feature) data and output (target) data from database \n",
    "x_data = df[features].values\n",
    "y_data = df[target].values\n",
    "\n",
    "# Split data for training and testing. In this example, the splits is 75:25\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data,test_size=0.25,random_state=40,shuffle=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fits and transforms x_train data set (standardisation)\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Transforms x_test data set using the mean and standard deviation from the fitted x_train data set\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Create a Gradient Boosting regressor\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [5, 10, 50]}\n",
    "GBR = GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(GBR, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(x_train_scaled, y_train.ravel())\n",
    "GBR_preds = grid_search.predict(x_test_scaled)\n",
    "\n",
    "# Print R2 and MSE for each combination\n",
    "results = grid_search.cv_results_\n",
    "mse_values = []\n",
    "for i in range(len(results['params'])):\n",
    "    params = results['params'][i]\n",
    "    model = GradientBoostingRegressor(**params)\n",
    "    model.fit(x_train_scaled, y_train.ravel())\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "    print(\"Parameters:\", params)\n",
    "    print(\"R2:\", r2)\n",
    "    print(\"MSE:\", mse)\n",
    "    print()\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the scores from the grid search results\n",
    "r2_scores = results['mean_test_score']\n",
    "\n",
    "# Create a list of parameter combinations\n",
    "param_combinations = [str(params) for params in results['params']]\n",
    "\n",
    "# Extract numeric parameter values\n",
    "param_values = [list(eval(params).values()) for params in param_combinations]\n",
    "\n",
    "# Plot R2 scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(len(r2_scores)), r2_scores, marker='o', color='purple')\n",
    "plt.xlabel('Parameter Combinations')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('R2 Score for Each Parameter Combination')\n",
    "plt.xticks(range(len(r2_scores)), param_values, rotation='vertical', fontsize=8) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(range(len(mse_values)), mse_values, color='dodgerblue')\n",
    "\n",
    "# Customizing the bar plot\n",
    "plt.xlabel('Parameter Combinations')\n",
    "plt.ylabel('MSE Score')\n",
    "plt.title('MSE Score for Each Parameter Combination')\n",
    "plt.xticks(range(len(mse_values)), param_values, rotation='vertical', fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670b240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
